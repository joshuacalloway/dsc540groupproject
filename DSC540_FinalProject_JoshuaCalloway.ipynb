{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joshuacalloway/dsc540groupproject/blob/main/StartingTrumpTweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLP on Trump's Tweets\n",
    "- Joshua Calloway\n",
    "- DSC 540, Fall Quarter - DePaul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "What problem are you tackling, and what's the setting you're considering? What data are you working on? Did anything change from the proposal regarding data, objectives, and methods that you will apply?\n",
    "\n",
    "\n",
    "We are looking Trump's tweets and applying NLP to see if we can determine the following\n",
    "- Sentiment Analysis\n",
    "- Subjectivity Analysis ( How objective or not are the tweets )\n",
    "- @readDonaldTrump contains tweets by Trump and also his publicity staff.  See if we can determine which are by Trump\n",
    "\n",
    "We are using tweets from thetrumparchive, which has about 50,0000 tweets and also another set with 1000 of Trump's latest tweets.  This is in alignment with the project proposal to use NLP on Trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We use Azure Predictive Analysis to create the GroundTruth sentiment labels\n",
    "- We get either positive, negative, or neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We then apply the following methods to build various sentiment classifiers and measure the accuracy against the GroundTruth test data\n",
    "\n",
    "## 1. Tweepy and TextBlob for analyzing sentiment\n",
    "## 2. LogisticsRegression using the Tweepy/TextBlob to fit the model\n",
    "## 3. NLTK Toolkit and NaiveBayesClassifier using the Tweepy/TextBlob labels to fit the model\n",
    "## 4. FastText with single label sentiment using the TweepyTextBlob labels to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data, Trump Tweets ( either 1000 or 55,0000 tweets )\n",
    "Here we use thetrumparchive to either fetch 1000 or larger set of 55,000 tweets.  The tweets come back as JSON in format of\n",
    "<code>\n",
    "{\n",
    "  id: 1\n",
    "  text: 'Lets win Michigan'\n",
    "  isRetweet: True\n",
    "  isDeleted: False\n",
    "  device: iPhone\n",
    "  favorites: 323,\n",
    "  retweets: 2\n",
    "  date: 2020-11-02\n",
    "}\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "BikM0IG41OX0"
   },
   "outputs": [],
   "source": [
    "import urllib.request, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrZYjcyF1b5l",
    "outputId": "5869b244-d003-4a79-f451-1b3f26c9377c"
   },
   "outputs": [],
   "source": [
    "# If LargeData is True, then we fetch 55,0000 tweets\n",
    "def fetch_data(largeData=False):\n",
    "    if largeData:\n",
    "        with open('tweets_11-06-2020.json') as f:\n",
    "            data = json.load(f)  # fetch 50,0000 tweets\n",
    "    else:\n",
    "        with urllib.request.urlopen(\"https://www.thetrumparchive.com/latest-tweets\") as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "    return DataFrame(data)\n",
    "\n",
    "# get_tweet_text = lambda tweet : tweet['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can either fetch 1000 or 55,000 tweets by switching the flag largeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "4U_YshEn1kFL",
    "outputId": "39a62dc0-c2e1-4b18-be0b-d1ded182e33e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>device</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1329963571250335744</td>\n",
       "      <td>https://t.co/YHscjY6G8t</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>76500</td>\n",
       "      <td>22413</td>\n",
       "      <td>2020-11-21T01:43:19.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329963296854847492</td>\n",
       "      <td>https://t.co/OLZnCJq93Y</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>55759</td>\n",
       "      <td>15486</td>\n",
       "      <td>2020-11-21T01:42:14.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1329963239170564098</td>\n",
       "      <td>https://t.co/cwOQLhQNFq</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>89705</td>\n",
       "      <td>24554</td>\n",
       "      <td>2020-11-21T01:42:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1329871920607744001</td>\n",
       "      <td>RT @WhiteHouse: LIVE: President @realDonaldTru...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>16786</td>\n",
       "      <td>2020-11-20T19:39:08.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1329871776889925636</td>\n",
       "      <td>...Why won’t they do it, and why are they so f...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>140901</td>\n",
       "      <td>23832</td>\n",
       "      <td>2020-11-20T19:38:34.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1329963571250335744                            https://t.co/YHscjY6G8t   \n",
       "1  1329963296854847492                            https://t.co/OLZnCJq93Y   \n",
       "2  1329963239170564098                            https://t.co/cwOQLhQNFq   \n",
       "3  1329871920607744001  RT @WhiteHouse: LIVE: President @realDonaldTru...   \n",
       "4  1329871776889925636  ...Why won’t they do it, and why are they so f...   \n",
       "\n",
       "   isRetweet  isDeleted              device favorites retweets  \\\n",
       "0      False      False  Twitter for iPhone     76500    22413   \n",
       "1      False      False  Twitter for iPhone     55759    15486   \n",
       "2      False      False  Twitter for iPhone     89705    24554   \n",
       "3       True      False  Twitter for iPhone         0    16786   \n",
       "4      False      False  Twitter for iPhone    140901    23832   \n",
       "\n",
       "                       date  \n",
       "0  2020-11-21T01:43:19.000Z  \n",
       "1  2020-11-21T01:42:14.000Z  \n",
       "2  2020-11-21T01:42:00.000Z  \n",
       "3  2020-11-20T19:39:08.000Z  \n",
       "4  2020-11-20T19:38:34.000Z  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we r interested in the text for NLP\n",
    "data = fetch_data(largeData=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We split the data into training, validation and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a Y with unknown value\n",
    "data['sentiment'] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['text']\n",
    "y = data['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=555)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.30, random_state=555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We use Azure Predictive Analysis to create the ground truth sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "credential = AzureKeyCredential(\"cb61d607e5c8402b9742b8aa40207593\")\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=\"https://trumptweetanalysissentiment.cognitiveservices.azure.com/\", credential=credential)\n",
    "    \n",
    "def call_azure(list_text_only_ten_items):\n",
    "    response = text_analytics_client.analyze_sentiment(list_text_only_ten_items)\n",
    "    successful_responses = [doc for doc in response if not doc.is_error]\n",
    "    return list_text_only_ten_items, list(map(lambda x: x['sentiment'], successful_responses))\n",
    "    \n",
    "# treat mixed and neutral sentiment as neutral\n",
    "def combine_mixed_neutral(sentiments):\n",
    "    converted = []\n",
    "    for item in sentiments:\n",
    "        newitem = 'neutral' if item == 'mixed' else item\n",
    "        converted.append(newitem)\n",
    "    return converted\n",
    "           \n",
    "# this is ground truth.  Using Azure sentiment\n",
    "def calculate_groundtruth_sentiment(list_of_texts):\n",
    "    sublists = np.split(np.array(list_of_texts.tolist()), list_of_texts.size / 10)\n",
    "    retvalues = list(map(lambda ls: call_azure(list(ls)), sublists))\n",
    "    sentiments = []\n",
    "    for item in retvalues:\n",
    "        sentiments.append(item[1])    \n",
    "    sentiments = [item for items in sentiments for item in items]\n",
    "    return list_of_texts, combine_mixed_neutral(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test_groundtruth = calculate_groundtruth_sentiment(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have groundtruth sentiment labels on test tweets, we will then try various methods and train on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Let's try tweepy and TextBlob to add Sentiment to each Tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Let's use a tweepy and TextBlob to add Sentiment to each Tweet\n",
    "\n",
    "Two blogs that use tweepy and TextBlob can be found at \n",
    "- https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/analyze-tweet-sentiment-in-python/\n",
    "- https://medium.com/better-programming/twitter-sentiment-analysis-15d8892c0082\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. We compute Sentiment of Tweet using TextBlob\n",
    "- polarity is whether or not the tweet is positive, negative, or neutral ( scaled from 1 to -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We r going to use tweepy and TextBlob for tweets\n",
    "import tweepy as tw\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "    return  TextBlob(text).sentiment.polarity\n",
    "\n",
    "# We eliminate words less then 3 characters long and standardize all words to lowercase\n",
    "def filter_words(words):\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
    "    return words_filtered\n",
    "\n",
    "\n",
    "# return neutral if small\n",
    "def calculateSentiment(text, neutralCutoff = 0.05):\n",
    "    polarity = getPolarity(text)\n",
    "    if abs(polarity) < neutralCutoff:\n",
    "        return 'neutral'\n",
    "    if polarity > 0:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X_test.apply(calculateSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(f'accuracy_score is {accuracy_score(Y_test_groundtruth, y_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we get 0.6 accuracy by guessing the neutralCutoff = 0.05.  Let's try to see if we can do better by trying different neutralCutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestAccuracy is at 0.67 with neutralCutoff at 0.22\n"
     ]
    }
   ],
   "source": [
    "from numpy import arange\n",
    "\n",
    "bestCutoff = 0.05\n",
    "bestAccuracy = 0.6\n",
    "\n",
    "for i in arange(0.0, 0.5, 0.02):\n",
    "    y_test_i = X_test.apply(calculateSentiment, neutralCutoff=i)\n",
    "    accuracy_i = accuracy_score(Y_test_groundtruth, y_test_i)\n",
    "    if accuracy_i > bestAccuracy:\n",
    "        bestAccuracy = accuracy_i\n",
    "        bestCutoff = i\n",
    "\n",
    "print(f'bestAccuracy is at {bestAccuracy} with neutralCutoff at {bestCutoff}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's recalculate the y_test with best neutralCutoff at 0.22\n",
    "y_test = X_test.apply(calculateSentiment, neutralCutoff=0.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is \n",
      "[[ 4 15  2]\n",
      " [ 2 48  4]\n",
      " [ 0 10 15]]\n"
     ]
    }
   ],
   "source": [
    "print(f'confusion matrix is \\n{confusion_matrix(Y_test_groundtruth, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.19      0.30        21\n",
      "     neutral       0.66      0.89      0.76        54\n",
      "    positive       0.71      0.60      0.65        25\n",
      "\n",
      "    accuracy                           0.67       100\n",
      "   macro avg       0.68      0.56      0.57       100\n",
      "weighted avg       0.67      0.67      0.63       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'classification report is \\n{classification_report(Y_test_groundtruth, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Let's try LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y = np.array([calculateSentiment(xi, neutralCutoff=0.22) for xi in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'negative', 'neutral',\n",
       "       'neutral', 'negative', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'negative', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'positive', 'neutral', 'negative', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'negative', 'neutral', 'negative',\n",
       "       'neutral', 'negative', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'neutral', 'negative', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'negative', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'neutral', 'negative', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'negative', 'neutral', 'neutral',\n",
       "       'negative', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'positive',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'negative', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'negative', 'neutral', 'neutral', 'positive', 'positive',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'negative', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'negative', 'neutral',\n",
       "       'neutral', 'positive', 'negative', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'negative', 'neutral', 'negative',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'negative',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'positive',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'negative', 'negative',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'negative', 'positive', 'negative', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'negative', 'neutral', 'positive', 'positive',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'negative', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'neutral', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    lowercase = False,\n",
    ")\n",
    "features = vectorizer.fit_transform(\n",
    "    data['text']\n",
    ")\n",
    "features_nd = features.toarray() # for easy usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.twilio.com/blog/2017/12/sentiment-analysis-scikit-learn.html\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_logistic, X_test_logistic, y_train_logistic, y_test_logistic  = train_test_split(\n",
    "        features_nd, \n",
    "        y,\n",
    "        train_size=0.90, \n",
    "        random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = log_model.fit(X=X_train_logistic, y=y_train_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.46\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy_score is {accuracy_score(Y_test_groundtruth, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "     neutral       0.74      0.86      0.80        73\n",
      "    positive       0.18      0.10      0.12        21\n",
      "\n",
      "    accuracy                           0.65       100\n",
      "   macro avg       0.31      0.32      0.31       100\n",
      "weighted avg       0.58      0.65      0.61       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. We can try the NLTK toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cat', 'is', 'very', 'cute']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def format_sentence(sent):\n",
    "    return({word: True for word in nltk.word_tokenize(sent)})\n",
    "\n",
    "print(nltk.word_tokenize(\"The cat is very cute\"))\n",
    "\n",
    "def format_sentence_with_sentement(sent):\n",
    "    formatted = format_sentence(sent)\n",
    "    sentement = calculateSentiment(sent, neutralCutoff = 0.22)\n",
    "    return [formatted, sentement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Stars': True, 'are': True, 'great': True, '!': True}, 'positive']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_sentence_with_sentement(\"Stars are great!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Rats': True, 'smell': True, 'very': True, 'bad': True}, 'negative']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_sentence_with_sentement(\"Rats smell very bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jc487/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                https://t.co/YHscjY6G8t\n",
       "1                                https://t.co/OLZnCJq93Y\n",
       "2                                https://t.co/cwOQLhQNFq\n",
       "3      RT @WhiteHouse: LIVE: President @realDonaldTru...\n",
       "4      ...Why won’t they do it, and why are they so f...\n",
       "                             ...                        \n",
       "995    RT @chefjclark: Amen ⁦@bkirkland7⁩! https://t....\n",
       "996      https://t.co/gsFSghkmdM https://t.co/zNoPFsTnn3\n",
       "997    Big problems and discrepancies with Mail In Ba...\n",
       "998    RT @realDonaldTrump: The Fake News Media is ri...\n",
       "999    RT @realDonaldTrump: Joe Biden called me Georg...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nltk = X.apply(format_sentence_with_sentement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'https': True, ':': True, '//t.co/YHscjY6G8t...\n",
       "1    [{'https': True, ':': True, '//t.co/OLZnCJq93Y...\n",
       "2    [{'https': True, ':': True, '//t.co/cwOQLhQNFq...\n",
       "3    [{'RT': True, '@': True, 'WhiteHouse': True, '...\n",
       "4    [{'...': True, 'Why': True, 'won': True, '’': ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nltk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = X_nltk[:int((.9)*len(X_nltk))]\n",
    "test =  X_nltk[int((.1)*len( X_nltk)):] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     WIN = True           positi : neutra =     28.6 : 1.0\n",
      "                    Fake = True           negati : positi =     26.1 : 1.0\n",
      "                 Corrupt = True           negati : neutra =     25.0 : 1.0\n",
      "                decision = True           negati : neutra =     25.0 : 1.0\n",
      "                  things = True           negati : neutra =     25.0 : 1.0\n",
      "                   Great = True           positi : neutra =     24.4 : 1.0\n",
      "                   place = True           negati : neutra =     19.3 : 1.0\n",
      "                       * = True           negati : neutra =     17.9 : 1.0\n",
      "                  Andrew = True           negati : neutra =     17.9 : 1.0\n",
      "                     FOR = True           negati : neutra =     17.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(training)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "example1 = \"America is great\"\n",
    "\n",
    "print(classifier.classify(format_sentence(example1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "example1 = \"Mail in ballots are fraudelent\"\n",
    "\n",
    "print(classifier.classify(format_sentence(example1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45555555555555555\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.util import accuracy\n",
    "print(accuracy(classifier, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the accuracy vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nltk_predict(sent):\n",
    "    return classifier.classify(format_sentence(sent))\n",
    "\n",
    "y_pred_nltk = X_test.apply(nltk_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.63\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy_score is {accuracy_score(Y_test_groundtruth, y_pred_nltk)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.94      0.64        31\n",
      "     neutral       0.96      0.57      0.72        42\n",
      "    positive       0.67      0.37      0.48        27\n",
      "\n",
      "    accuracy                           0.63       100\n",
      "   macro avg       0.70      0.63      0.61       100\n",
      "weighted avg       0.73      0.63      0.63       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_groundtruth, y_pred_nltk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. We train a FaceBook FastText model to build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let try cleaning the Tweets to see if we can get a better ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to get better accuracy by cleaning the tweets text\n",
    "# Define some cleaning methods for the Tweet Text\n",
    "# Create a function to clean the tweets\n",
    "import re\n",
    "import string\n",
    "\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_doublespace(text):\n",
    "    text = re.sub('  +', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_doublespace('    ') == ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punct(\"Hello this is josh!!!\") == \"Hello this is josh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(remove_punct)\n",
    "data['text'] = data['text'].apply(remove_doublespace)\n",
    "\n",
    "data['sentiment'] = data['text'].apply(calculateSentiment)\n",
    "X = data['text']\n",
    "y = data['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=555)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.30, random_state=555)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test_groundtruth = calculate_groundtruth_sentiment(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.12      0.20        16\n",
      "     neutral       0.47      0.85      0.61        47\n",
      "    positive       0.27      0.08      0.12        37\n",
      "\n",
      "    accuracy                           0.45       100\n",
      "   macro avg       0.41      0.35      0.31       100\n",
      "weighted avg       0.40      0.45      0.36       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pennsylvania Party Leadership votes are this week I hope they pick very tough and smart fighters We will WIN'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr = ''\n",
    "mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[357] == mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'text': ['hello', '', ' ']}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text\n",
       "0  hello\n",
       "1       \n",
       "2       "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = df[(df['text'] == '') | (df['text'].str.isspace())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text\n",
       "1     \n",
       "2     "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       httpstcoYHscjYGt\n",
       "1                                       httpstcoOLZnCJqY\n",
       "2                                     httpstcocwOQLhQNFq\n",
       "3      RT WhiteHouse LIVE President realDonaldTrump g...\n",
       "4      Why won’t they do it and why are they so fast ...\n",
       "                             ...                        \n",
       "995     RT chefjclark Amen ⁦bkirkland⁩ httpstcohWKODkDmT\n",
       "996                 httpstcogsFSghkmdM httpstcozNoPFsTnn\n",
       "997    Big problems and discrepancies with Mail In Ba...\n",
       "998    RT realDonaldTrump The Fake News Media is ridi...\n",
       "999    RT realDonaldTrump Joe Biden called me George ...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       neutral\n",
       "1       neutral\n",
       "2       neutral\n",
       "3      positive\n",
       "4      negative\n",
       "         ...   \n",
       "995     neutral\n",
       "996     neutral\n",
       "997     neutral\n",
       "998    negative\n",
       "999     neutral\n",
       "Name: sentiment, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test_groundtruth, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'negative', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'negative', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'neutral'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPW+nXq5kNmMD0i1KQMwvga",
   "include_colab_link": true,
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (dsc540)",
   "language": "python",
   "name": "dsc540"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
